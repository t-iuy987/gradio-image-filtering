{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5c75216",
   "metadata": {},
   "source": [
    "Data Science Gradio Image Filtering<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d953f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeb0dce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from PIL import Image\n",
    "from scipy  import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557c6fef",
   "metadata": {},
   "source": [
    "<h3>Grayscale an Image</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4462c6",
   "metadata": {},
   "source": [
    "Formula: Grayscale = 0.299R + 0.587G + 0.114B <br>\n",
    "Source: https://www.dynamsoft.com/blog/insights/image-processing/image-processing-101-color-space-conversion/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c598829",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grayscale = [0.299, 0.587,  0.114]\n",
    "def grayscale(img):\n",
    "\n",
    "    # multiply with weights \n",
    "    red = np.array(img[:, :, 0]) * Grayscale[0] # 0 = first channel i.e., red\n",
    "    green = np.array(img[:, :, 1]) * Grayscale[1] # 1 = second channel i.e., green\n",
    "    blue = np.array(img[:, :, 2]) * Grayscale[2] # 2 = third channel i.e., blue\n",
    "    \n",
    "    # add the weights\n",
    "    sum = (red+green+blue)\n",
    "\n",
    "    grayImage = np.zeros(img.shape) # make a new image with the same shape as 'img' filled w zeroes\n",
    "    grayImage = img.copy() # copy the original image \n",
    "\n",
    "    # now, change the color channels to gray\n",
    "    for i in range(3):\n",
    "        grayImage[:,:,i] = sum\n",
    "\n",
    "    return grayImage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab2e2c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Interface(fn=grayscale,\n",
    "                    inputs=\"image\", \n",
    "                    outputs=\"image\",\n",
    "                    title=\"Grayscale an Image\",\n",
    "                    description=\"Upload an image and grayscale it.\",\n",
    "                    theme=gr.themes.Soft())\n",
    "demo.launch() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a86a04",
   "metadata": {},
   "source": [
    "<h3>Blur an Image</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23233faa",
   "metadata": {},
   "source": [
    "Gaussian blur <br>\n",
    " - reduce image noise and smooth out details of an image\n",
    " - working\n",
    "   averages the pixel values in the image using a Gaussian function\n",
    " - Gaussian function : \n",
    "     - bell curve shape with a peak at the center and lower values on either side\n",
    "     - applying this function to each pixel in an image assigns a higher weight to the pixel values close to the center and lower weights to the pixel values farther from the center.\n",
    " - How?\n",
    "      - reducing the sharpness of edges\n",
    "      - reduce the fine details in the image\n",
    "      - reduces the contrast between different parts of the image\n",
    "      - reduces the sharpness of transitions between different colors or intensities\n",
    " - ![This is a alt text.](https://i.stack.imgur.com/U7vYB.gif \"This is a sample image.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f3a719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussianKernel(kernel_size, sigma):\n",
    "    x, y = np.mgrid[-kernel_size//2 + 1 : kernel_size//2 + 1, -kernel_size//2 + 1:kernel_size//2 + 1] # create a 2d grid and store the coordinates (x,y) of each pixel in this grid\n",
    "    # applying formula\n",
    "    kernel =   np.exp(-((x**2 + y**2) / (2.0*sigma**2))) \n",
    "    kernel = (1/(2*np.pi*(sigma)**2)) * kernel\n",
    "    return kernel\n",
    "\n",
    "\n",
    "def blur_img( Sigma,  Image):\n",
    "    kernel = gaussianKernel(11, Sigma)\n",
    "    Image = cv2.resize(Image, (512,512)) # resize the image \n",
    "    img_blurred = cv2.filter2D(Image,-1,kernel) #convolve: dot product of kernel and each pixel of the image,  -1 : output should also be image\n",
    "\n",
    "    return img_blurred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80cb2605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Interface(fn=blur_img,\n",
    "                    inputs=[ gr.Slider(1, 10, value=3, step=1 ,label=\"Sigma\", info=\"Choose betwen 1 and 10\"),  \"image\"], \n",
    "                    outputs=\"image\",\n",
    "                    title=\"Blur an Image with Gaussian Blur\",\n",
    "                    description=\"Upload an image and blur it.\",\n",
    "                    theme=gr.themes.Soft())\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691078a0",
   "metadata": {},
   "source": [
    "<h3>Canny Edge Detection</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05046054",
   "metadata": {},
   "source": [
    "Step1: Gaussian Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "645d1910",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussiankernel(kernel_size, sigma):\n",
    "    x, y = np.mgrid[-kernel_size//2 + 1:kernel_size//2 + 1, -kernel_size//2 + 1:kernel_size//2 + 1]\n",
    "    kernel =   np.exp(-((x**2 + y**2) / (2.0*sigma**2))) \n",
    "    kernel = (1/(2*np.pi*(sigma)**2)) * kernel\n",
    "    return kernel\n",
    "\n",
    "def gaussianFilter(img, kernel_size, sigma):\n",
    "    img = cv2.resize(np.array(img), (512,512)) # resize image\n",
    "    img = grayscale(img) # grayscale the image, because gaussian filter is mostly to grayscale images\n",
    "\n",
    "    kernel = gaussiankernel(kernel_size, sigma) # find kernel\n",
    "    img_n = img[:,:,0] #  convert to 2d \n",
    "    img_smoothed =  ndimage.convolve(img_n,kernel) # apply the kernel\n",
    "    return img_smoothed\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84e79f0",
   "metadata": {},
   "source": [
    "Step 2: Intensity gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b198d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying sobel filters which detect changes in intensity between neighboring pixels in an image, computes gradient of the image intensity in the x and y directions\n",
    "def intensity_gradient(img_smoothed): #  computes the magnitude and direction of the image gradient using the Sobel filters.\n",
    "    x = cv2.Sobel(img_smoothed, cv2.CV_64F, 1, 0, ksize=3) # CV_64F: output data type of image,1: for x, 0: for y, ksize = 3x3\n",
    "    y = cv2.Sobel(img_smoothed, cv2.CV_64F, 0, 1, ksize=3)\n",
    "\n",
    "    G = (x ** 2 + y ** 2) ** 0.5 # magnitude\n",
    "    theta = np.rad2deg(np.arctan2(y, x)) # direction\n",
    "    return G, theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b73fe8",
   "metadata": {},
   "source": [
    "Step 3: Non-maximum suppression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e45a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# non maximum suppression thins out edges and highlight only the most prominent ones\n",
    "def non_max_suppression(G, theta):\n",
    "    direction = theta \n",
    "    direction[direction < 0] += 180\n",
    "    r, c = G.shape[:2]\n",
    "    NMS = np.zeros((r, c), dtype=np.int32)\n",
    "    \n",
    "    #for each pixel in the image,check whether its gradient magnitude is the maximum along the gradient direction. If it is, the pixel is kept, otherwise it is set to zero\n",
    "    for i in range(1,r-1):\n",
    "        for j in range(1,c-1):\n",
    "            pix_1 = 255\n",
    "            pix_2 = 255\n",
    "            if (0 <= direction[i,j] < 22.5) or (157.5 <= direction[i,j] <= 180):\n",
    "                pix_1 = G[i, j+1] # right\n",
    "                pix_2 = G[i, j-1] # left\n",
    "            \n",
    "            elif (22.5 <= direction[i,j] < 67.5):\n",
    "                pix_1 = G[i+1, j-1] # down and left\n",
    "                pix_2 = G[i-1, j+1] # up and right\n",
    "            \n",
    "            elif (67.5 <= direction[i,j] < 112.5):\n",
    "                pix_1 = G[i+1, j] # down\n",
    "                pix_2 = G[i-1, j] # up\n",
    "            \n",
    "            elif (112.5 <= direction[i,j] < 157.5):\n",
    "                pix_1 = G[i-1, j-1] # above and left\n",
    "                pix_2 = G[i+1, j+1] # down and right\n",
    "\n",
    "            if (G[i,j] >= pix_1) and (G[i,j] >= pix_2): #if gradient magnitude is the maximum along the gradient direction\n",
    "                NMS[i,j] = G[i,j]\n",
    "            else:\n",
    "                NMS[i,j] = 0\n",
    "    return NMS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9f85e",
   "metadata": {},
   "source": [
    "Step 4: Double Threshhold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1072cba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_threshold(NMS, high_thresh, low_thresh, weak_pixel, strong_pixel):\n",
    "    highThreshold = NMS.max() * high_thresh; # max val in NMS * high thresh\n",
    "    lowThreshold = highThreshold * low_thresh;\n",
    "\n",
    "    m,n = NMS.shape\n",
    "    double_thresh = np.zeros((m,n), dtype=np.int32)\n",
    "\n",
    "    i, j = np.where(NMS >= highThreshold)\n",
    "    strong = np.int32(strong_pixel)\n",
    "    double_thresh[i, j] = strong\n",
    "    \n",
    "    i, j = np.where((NMS <= highThreshold) & (NMS >= lowThreshold))\n",
    "    weak = np.int32(weak_pixel)\n",
    "    double_thresh[i, j] = weak\n",
    "    \n",
    "    return double_thresh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e416d83",
   "metadata": {},
   "source": [
    "Step 5: Edge tracking by hysteresis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a3aa5ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  form continuous curves or lines\n",
    "def hysteresis(double_thresh, weak_pixel, strong_pixel):\n",
    "    r, c  = double_thresh.shape\n",
    "\n",
    "    # for each pixel in the double threshold image\n",
    "    for i in range(1, r-1):\n",
    "        for j in range(1, c-1): # If at least one of the neighboring 8 pixels is a strong pixel, the weak pixel is promoted to a strong pixel\n",
    "            if (double_thresh[i,j] == weak_pixel):\n",
    "                if ((double_thresh[i+1, j-1] == strong_pixel) or (double_thresh[i+1, j] == strong_pixel) or (double_thresh[i+1, j+1] == strong_pixel) or (double_thresh[i, j-1] == strong_pixel) or (double_thresh[i, j+1] == strong_pixel)or (double_thresh[i-1, j-1] == strong_pixel) or (double_thresh[i-1, j] == strong_pixel) or (double_thresh[i-1, j+1] == strong_pixel)):\n",
    "                    double_thresh[i, j] = strong_pixel\n",
    "                else:\n",
    "                    double_thresh[i, j] = 0\n",
    "    return double_thresh\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b56ca942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(img):\n",
    "    i = img.astype(np.uint8)\n",
    "    cv2.imshow('Original', i)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \n",
    "def canny_detection(img, sigma, low_thresh, high_thresh, step):\n",
    "    if step == \"\":\n",
    "        raise gr.Error(\"Select a Step!\")\n",
    "    if step == \"Input Image\":\n",
    "        return grayscale(img)\n",
    "    elif step == \"Gaussian Smoothing\":\n",
    "        return gaussianFilter(img, 11, sigma)\n",
    "    elif step == \"Intensity Gradient: Magnitude\":\n",
    "        img_smoothed = gaussianFilter(img, 11, sigma)\n",
    "        G, theta = intensity_gradient(img_smoothed)\n",
    "        return G.astype(np.uint8)\n",
    "    elif step == \"Intensity Gradient: Theta\":\n",
    "        img_smoothed = gaussianFilter(img, 11, sigma)\n",
    "        G, theta = intensity_gradient(img_smoothed)\n",
    "        return theta.astype(np.uint8)\n",
    "    elif step == \"Non-maximum Suppression\":\n",
    "        img_smoothed = gaussianFilter(img, 11, sigma)\n",
    "        G, theta = intensity_gradient(img_smoothed)\n",
    "        return  non_max_suppression(G, theta)\n",
    "    elif step == \"Double Threshold\":\n",
    "        img_smoothed = gaussianFilter(img, 11, sigma)\n",
    "        G, theta = intensity_gradient(img_smoothed)\n",
    "        Z = non_max_suppression(G, theta)\n",
    "        return double_threshold(Z, low_thresh, high_thresh, 120, 255)\n",
    "    elif step == \"Hysteresis threshold\":\n",
    "        img_smoothed = gaussianFilter(img, 11, sigma)\n",
    "        G, theta = intensity_gradient(img_smoothed)\n",
    "        Z = non_max_suppression(G, theta)\n",
    "        R = double_threshold(Z, low_thresh, high_thresh, 120, 255)\n",
    "        return hysteresis(R, 120, 255)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "92d058bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Interface(fn=canny_detection,\n",
    "                    inputs=\n",
    "                    [\"image\",\n",
    "                     gr.Slider(1, 10, value=3, step=1 ,label=\"Sigma\", info=\"Choose betwen 1 and 10\"), \n",
    "                     gr.Slider(0, 1, value=0.15, step=0.01 ,label=\"Low Threshold\"),\n",
    "                     gr.Slider(0, 1, value=0.50, step=0.01 ,label=\"High Threshold\"),                     \n",
    "                     gr.Dropdown([\"Input Image\",\"Gaussian Smoothing\", \"Intensity Gradient: Magnitude\", \"Intensity Gradient: Theta\", \"Non-maximum Suppression\", \"Double Threshold\", \"Hysteresis threshold\"], label=\"Step\", info=\"Choose a step from Canny Edge Detection.\")\n",
    "                    ], \n",
    "                    outputs=\"image\",\n",
    "                    title=\"Canny Edge Detection\",\n",
    "                    description=\"This demonstration shows the 5 steps of the classical Canny edge detector.\",\n",
    "                    theme=gr.themes.Soft())\n",
    "\n",
    "\n",
    "demo.launch() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2b1df0",
   "metadata": {},
   "source": [
    "<h3>Invert Colors of an Image</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89319c54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert(image):\n",
    "    rgb_channels = image[:,:,:3] # contains all the rows and columns of the original image array, but only the first three channels (i.e., the RGB channels)\n",
    "    \n",
    "    # subtract 255 from each pixel to invert the image\n",
    "    inverted_image = 255 - rgb_channels\n",
    "    inverted_image = Image.fromarray(inverted_image)\n",
    "    return inverted_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9913ce4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo = gr.Interface(fn=invert,\n",
    "                    inputs=\"image\", \n",
    "                    outputs=\"image\",\n",
    "                    title=\"Invert colors of an image\",\n",
    "                    description=\"Upload an image and invert its colors.\",\n",
    "                    theme=gr.themes.Soft())\n",
    "demo.launch() "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
